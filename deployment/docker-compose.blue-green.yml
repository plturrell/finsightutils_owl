version: '3.8'

# Blue-Green deployment configuration for OWL with NVIDIA GPU support
# This setup enables zero-downtime deployments by running two identical
# environments ("blue" and "green") that can be switched with a proxy

services:
  # Nginx load balancer for blue-green switching
  nginx:
    image: nginx:1.25-alpine
    container_name: owl-nginx
    ports:
      - "8000:80"  # Main application port
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/conf.d:/etc/nginx/conf.d
    depends_on:
      - api-blue
      - api-green
    restart: unless-stopped
    networks:
      - owl-network

  # Blue environment
  api-blue:
    build:
      context: ..
      dockerfile: deployment/Dockerfile.api
    image: finsight/owl-api:blue
    container_name: owl-api-blue
    expose:
      - "8000"
    environment:
      - LAYOUT_MODEL_URL=triton-blue:8000/v2/models/nv-layoutlm-financial
      - TABLE_MODEL_URL=triton-blue:8000/v2/models/nv-table-extraction
      - NER_MODEL_URL=triton-blue:8000/v2/models/nv-financial-ner
      - USE_GPU=true
      - BASE_URI=http://finsight.dev/kg/
      - INCLUDE_PROVENANCE=true
      - DEPLOYMENT_COLOR=blue
    volumes:
      - ../data:/app/data
    depends_on:
      - triton-blue
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: 1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - owl-network
              
  owl-converter-blue:
    build:
      context: ..
      dockerfile: deployment/Dockerfile.owl
    image: finsight/owl-converter:blue
    container_name: owl-converter-blue
    expose:
      - "8000"
    environment:
      - BASE_URI=http://finsight.dev/ontology/sap/
      - INFERENCE_LEVEL=standard
      - OUTPUT_DIR=/app/results
      - DEPLOYMENT_COLOR=blue
    volumes:
      - owl_results_blue:/app/results
    restart: unless-stopped
    networks:
      - owl-network

  triton-blue:
    image: nvcr.io/nvidia/tritonserver:23.10-py3
    container_name: owl-triton-blue
    expose:
      - "8000"  # HTTP
      - "8001"  # gRPC
      - "8002"  # Metrics
    environment:
      - LD_LIBRARY_PATH=/opt/tritonserver/lib
    volumes:
      - ../nvidia_triton/model_repository:/models
    command: ["tritonserver", "--model-repository=/models", "--strict-model-config=false", "--log-verbose=1"]
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: 1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v2/health/ready"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 60s
    networks:
      - owl-network

  # Green environment
  api-green:
    build:
      context: ..
      dockerfile: deployment/Dockerfile.api
    image: finsight/owl-api:green
    container_name: owl-api-green
    expose:
      - "8000"
    environment:
      - LAYOUT_MODEL_URL=triton-green:8000/v2/models/nv-layoutlm-financial
      - TABLE_MODEL_URL=triton-green:8000/v2/models/nv-table-extraction
      - NER_MODEL_URL=triton-green:8000/v2/models/nv-financial-ner
      - USE_GPU=true
      - BASE_URI=http://finsight.dev/kg/
      - INCLUDE_PROVENANCE=true
      - DEPLOYMENT_COLOR=green
    volumes:
      - ../data:/app/data
    depends_on:
      - triton-green
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: 1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - owl-network
              
  owl-converter-green:
    build:
      context: ..
      dockerfile: deployment/Dockerfile.owl
    image: finsight/owl-converter:green
    container_name: owl-converter-green
    expose:
      - "8000"
    environment:
      - BASE_URI=http://finsight.dev/ontology/sap/
      - INFERENCE_LEVEL=standard
      - OUTPUT_DIR=/app/results
      - DEPLOYMENT_COLOR=green
    volumes:
      - owl_results_green:/app/results
    restart: unless-stopped
    networks:
      - owl-network

  triton-green:
    image: nvcr.io/nvidia/tritonserver:23.10-py3
    container_name: owl-triton-green
    expose:
      - "8000"  # HTTP
      - "8001"  # gRPC
      - "8002"  # Metrics
    environment:
      - LD_LIBRARY_PATH=/opt/tritonserver/lib
    volumes:
      - ../nvidia_triton/model_repository:/models
    command: ["tritonserver", "--model-repository=/models", "--strict-model-config=false", "--log-verbose=1"]
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: 1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v2/health/ready"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 60s
    networks:
      - owl-network

  # Monitoring (shared between blue and green)
  prometheus:
    image: prom/prometheus:v2.43.0
    container_name: owl-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/blue-green.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    restart: unless-stopped
    networks:
      - owl-network

  grafana:
    image: grafana/grafana:9.5.1
    container_name: owl-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    restart: unless-stopped
    networks:
      - owl-network

  # NVIDIA DCGM Exporter for GPU metrics
  dcgm-exporter:
    image: nvcr.io/nvidia/k8s/dcgm-exporter:3.1.7-3.1.4-ubuntu20.04
    container_name: owl-dcgm-exporter
    ports:
      - "9400:9400"
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: 1
    networks:
      - owl-network

volumes:
  prometheus_data:
  grafana_data:
  owl_results_blue:
  owl_results_green:

networks:
  owl-network:
    driver: bridge